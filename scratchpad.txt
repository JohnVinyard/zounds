Pattern tests
====================================
finish tests
add MongoDB controller and ensure all tests are passing
Buffer management scheme
Implement Zound.play() method
"live" JACK tests
Move tests that have nothing to do with data storage/access into the model package


TemplateMatch tweaks
====================================
- Upload/record query sounds in websearch.py

- dragger/slider for playhead positioning

- Display timecodes in websearch interface

- How does correlation compare with euclidean distance once all patches have
  unit norm, both in terms of speed and
  
- Once the Templates are learned, take the DCT of each and sparsify to speed
  up analysis?
  
- How about the distance between random samples of the patches?

- 2d fft performance (as compared to TemplateMatch)?
- Try RBM and autoencoder for learning patch centroids, instead of KMeans
- Multiscale kmeans, i.e., do TemplateMatch on multiple scales
- Expectation-Maximization clustering
- Try lowpass filter subtraction method for spectrogram sharpening

- There's something wrong about the way I'm doing searches with the TemplateMatch
  semantic hashing features. It's most obvious when silence (or near-silence) is
  present in a query.  These searches demonstrate problems:
  
    http://zounds.co/?q=107750bfe7774f9aa1f8b778944b4ca7:130:260
    
	http://localhost:8080/zoundsapp?q=bcdce3a074c24708bada301df9b764a2:0:124
	http://localhost:8080/zoundsapp?q=62c67ee8b3ad4d648e2b411a77f4e661:0:114
	http://localhost:8080/zoundsapp?q=e5acc136103245b2982506a2b37955bd:169:290
	http://localhost:8080/zoundsapp?q=f62dc6f1bdb04f5bad3b0984a1b3c0b9:0:95
	http://localhost:8080/zoundsapp?q=745f909faccd4cee98cab19139b5bb66:14:103
	http://localhost:8080/zoundsapp?q=1b902c831b564dbfb54055f7f29d1ea4:67:115
	http://localhost:8080/zoundsapp?q=b376c4575f6e41538e5b31d876215d6d:0:86 (need better resolution)
	
Audio Encoding
===================================
Why is FFT resolution insufficient at low frequencies?
Why does VQ coding work so poorly?
How can upsampling be performed without aliasing?
How does the human brain represent noise?


Music
=================================

TODO:
===========
TimeSeries class
Transforms (make sure that transforms are an ordered list, and not a dictionary!)
Pattern tests
Heuristic for deciding when a Pattern must be rendered, analyzed, and stored in the
frames database
Handle mp3 files


upload or record query sounds
ogg vorbis or mp3 storage?
Audio hosted elsewhere, i.e., I store the features, but the audio is hosted on SoundCloud, e.g.
Pattern data structure
Update indexes on-the-fly
onset detection
pitch
chroma
loudness
"effects" - amplitude, time and pitch stretch, reverb
client and at-home player


  
Good Searches
=================
http://localhost/?q=8f906adb408f4475b68fee94447876af:31:178
http://localhost/?q=087744117a6b40b2ac40a17802b2968c:14:65


- Add option to search.py to draw sounds randomly from a database, or from
  a directory
  	
- Limit search sizes

- Limit size of image and audio requests

- start a planning document for the higher level/ more abstract stuff




 